## Deep Cross-modal Retrieval

Stacked Cross Attention for Image-Text Matching, ECCV 2018. [[paper]](https://arxiv.org/abs/1803.08024) [[code]](https://github.com/kuanghuei/SCAN)

Multi-Level Visual-Semantic Alignments with Relation-Wise Dual Attention Network for Image and Text Matching, IJCAI 2019. [[paper]](https://www.ijcai.org/proceedings/2019/0111.pdf)

Position Focused Attention Network for Image-Text Matching, IJCAI 2019. [[paper]](https://arxiv.org/abs/1907.09748) [[code]](https://github.com/HaoYang0123/Position-Focused-Attention-Network)

Visual Semantic Reasoning for Image-Text Matching, ICCV 2019. [[paper]](https://arxiv.org/abs/1909.02701) [[code]](https://github.com/KunpengLi1994/VSRN)

CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval, ICCV 2019. [[paper]](https://arxiv.org/abs/1909.05506) [[code]](https://github.com/ZihaoWang-CV/CAMP_iccv19)

Focus Your Attention: A Bidirectional Focal Attention Network for Image-Text Matching, ACM MM 2019. [[paper]](https://arxiv.org/abs/1909.11416)

Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval, WACV 2020. [[paper]](https://arxiv.org/abs/1910.05134)

Multi-Modality Cross Attention Network for Image and Sentence Matching, CVPR 2020. [[paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Wei_Multi-Modality_Cross_Attention_Network_for_Image_and_Sentence_Matching_CVPR_2020_paper.html)

IMRAM: Iterative Matching with Recurrent Attention Memory for Cross-Modal Image-Text Retrieval, CVPR 2020. [[paper]](https://arxiv.org/abs/2003.03772) [[code]](https://github.com/HuiChen24/IMRAM)

Context-Aware Attention Network for Image-Text Retrieval, CVPR 2020. [[paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Context-Aware_Attention_Network_for_Image-Text_Retrieval_CVPR_2020_paper.pdf)

Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching, AAAI 2020. [[paper]](https://arxiv.org/abs/2002.08510)

Similarity Reasoning and Filtration for Image-Text Matching, AAAI 2021. [[paper]](https://arxiv.org/abs/2101.01368) [[code]](https://github.com/Paranioar/SGRAF)


## Deep Cross-modal Hashing Retrieval

Deep Cross-Modal Hashing, CVPR 2017. [[paper]](https://arxiv.org/abs/1602.02255) [[code]](https://github.com/jiangqy/DCMH-CVPR2017)

Deep visual-semantic hashing for cross-modal retrieval, KDD 2016. [[paper]](http://www.kdd.org/kdd2016/papers/files/rpp0086-caoA.pdf)

Pairwise relationship guided deep hashing for cross-modal retrieval, AAAI 2017. [[paper]](https://see.xidian.edu.cn/faculty/chdeng/Welcome%20to%20Cheng%20Deng%27s%20Homepage_files/Papers/Conference/AAAI2017_Erkun.pdf)

Self-supervised adversarial hashing networks for cross-modal retrieval, CVPR 2018. [[paper]](https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Self-Supervised_Adversarial_Hashing_CVPR_2018_paper.pdf)

Cross-Modal Hamming Hashing, ECCV 2018. [[paper]](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yue_Cao_Cross-Modal_Hamming_Hashing_ECCV_2018_paper.pdf)

Attention-aware deep adversarial hashing for cross-modal retrieval, ECCV 2018. [[paper]](https://arxiv.org/abs/1711.09347)

Triplet-Based Deep Hashing Network for Cross-Modal Retrieval, TIP 2018. [[paper]](https://arxiv.org/abs/1904.02449)
